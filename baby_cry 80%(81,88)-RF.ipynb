{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:35: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:597: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:836: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1097: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1344: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1480: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:152: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  precompute=False, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:320: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, random_state=None,\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:580: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=4 * np.finfo(np.float).eps, n_jobs=None,\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:31: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n"
     ]
    }
   ],
   "source": [
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile as wav\n",
    "from sklearn import metrics \n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, LayerNormalization,MaxPool2D\n",
    "from keras.layers import Activation, Dense, Dropout, Conv2D, Flatten, MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling1D, AveragePooling2D, Input, Add\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical \n",
    "from python_speech_features import mfcc, logfbank\n",
    "import csv\n",
    "import os\n",
    "from keras import layers\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = 'filename'\n",
    "for i in range(1, 26):\n",
    "    header += f' mfcc{i}'\n",
    "header += ' label'\n",
    "header = header.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('dataset.csv', 'w', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "genres = 'cry no_cry'.split()\n",
    "for g in genres:\n",
    "    for filename in os.listdir(f'ba_cry/{g}'):\n",
    "        songname = f'ba_cry/{g}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=7)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr,n_mfcc=25)\n",
    "        to_append = f'{filename}'    \n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        to_append += f' {g}'\n",
    "        file = open('dataset.csv', 'a', newline='')\n",
    "        with file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(to_append.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset.csv')\n",
    "data.head()# Dropping unneccesary columns\n",
    "data = data.drop(['filename'],axis=1)#Encoding the Labels\n",
    "genre_list = data.iloc[:, -1]\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(genre_list)#Scaling the Feature columns\n",
    "scaler = StandardScaler()\n",
    "# X =np.array(data.iloc[:, :-1], dtype = float)\n",
    "X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))#Dividing data into training and Testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# model.add(Conv2D(16, (3, 3), activation='relu', strides=(1, 1),padding='same', input_shape=X_train.shape[1]))\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu', strides=(1, 1),padding='same')) \n",
    "# model.add(Conv2D(64, (3, 3), activation='relu', strides=(1, 1),padding='same'))\n",
    "# model.add(MaxPool2D ((2, 2)))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train,shuffle=True,epochs=50,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('ff_nn_v3_Ac88_best.h5')\n",
    "model.load_weights('ff_nn_v3_Ac88_best_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* recording\n",
      "* done recording\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 2\n",
    "RATE = 44100\n",
    "RECORD_SECONDS = 5\n",
    "WAVE_OUTPUT_FILENAME = \"output.wav\"\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"* recording\")\n",
    "\n",
    "frames = []\n",
    "\n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "\n",
    "print(\"* done recording\")\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n",
    "wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "wf.setframerate(RATE)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = 'filename'\n",
    "for i in range(1, 26):\n",
    "    header += f' mfcc{i}'\n",
    "header += ' label'\n",
    "header = header.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('predict.csv', 'w', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "y, sr = librosa.load('output.wav', mono=True, duration=5)\n",
    "mfcc = librosa.feature.mfcc(y=y, sr=sr,n_mfcc=25)\n",
    "to_append = f'output.wav '   \n",
    "for e in mfcc:\n",
    "    to_append += f' {np.mean(e)}'\n",
    "file = open('predict.csv', 'a', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(to_append.split())\n",
    "live_data = pd.read_csv('predict.csv')\n",
    "live_data = live_data.drop(['filename'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output.wav\n"
     ]
    }
   ],
   "source": [
    "op=list(to_append.split())\n",
    "print(op.pop(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-383.49456787109375', '100.76104736328125', '13.4022216796875', '32.64509963989258', '12.863853454589844', '4.169948101043701', '2.1110963821411133', '-1.8287122249603271', '-10.638762474060059', '10.564427375793457', '0.8306987881660461', '4.8464837074279785', '1.9661191701889038', '3.62606143951416', '3.008317708969116', '6.592686176300049', '-4.3055419921875', '1.432627558708191', '-0.5799728035926819', '3.029869556427002', '-3.412336587905884', '0.638687789440155', '-1.7327020168304443', '2.0981388092041016', '-4.872173309326172']\n",
      "[[-0.4745465   1.04202753  1.27148003  1.59036564  1.38051076  0.10011212\n",
      "   0.62507151 -0.5104022  -1.0130688   1.04684654  0.27183806  0.40394291\n",
      "   0.40240906  0.01695611  0.40928814  0.39679809 -0.71165938 -0.19917914\n",
      "   0.11264307  0.13188081 -0.40059197 -0.37477491  0.01371644  0.16830556\n",
      "  -1.03931743]]\n",
      "WARNING:tensorflow:From <ipython-input-11-81ef59356b00>:4: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "Predicted=[1]\n",
      "No cry\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(op)\n",
    "Xnew = scaler.transform([op])\n",
    "print(Xnew)\n",
    "ynew = model.predict_classes(Xnew)\n",
    "print(\"Predicted=%s\" % (ynew))\n",
    "if ynew==0:\n",
    "    print('Cry')\n",
    "else:\n",
    "    print('No cry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xnew = np.array([live_data.iloc[0][0:25]])\n",
    "# print(Xnew)\n",
    "# ynew = model.predict_classes(Xnew)\n",
    "# print(\"Predicted=%s\" % (ynew))\n",
    "# if ynew==0:\n",
    "#     print('Cry')\n",
    "# else:\n",
    "#     print('No cry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* recording\n",
      "output0.wav\n",
      "Predicting\n",
      "output1.wav\n",
      "Predicted=[0]\n",
      "Cry\n",
      "Predicting\n",
      "output2.wav\n",
      "Predicted=[0]\n",
      "Cry\n",
      "Predicting\n",
      "output3.wav\n",
      "Predicted=[0]\n",
      "Cry\n",
      "Predicting\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted=[0]\n",
      "Cry\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import pathlib\n",
    "import threading\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# t1 = threading.Thread(target=print_square, args=(10,))\n",
    "# t2 = threading.Thread(target=print_cube, args=(10,))\n",
    "\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 2\n",
    "RATE = 44100\n",
    "RECORD_SECONDS = 5\n",
    "WAVE_OUTPUT_FILENAME = \"output.wav\"\n",
    "\n",
    "stop = 0\n",
    "\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"* recording\")\n",
    "\n",
    "\n",
    "def predict(name):\n",
    "    #Doing prediction\n",
    "    cmap = plt.get_cmap('inferno')\n",
    "    plt.figure(figsize=(8,8))\n",
    "    pathlib.Path(f'live_data/').mkdir(parents=True, exist_ok=True)\n",
    "    # for filename in os.listdir(f'b_cry/{g}'):\n",
    "    songname = name+'.wav'\n",
    "    y, sr = librosa.load(songname, mono=True, duration=7)\n",
    "    plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
    "    plt.axis('off');\n",
    "    plt.savefig(f'live_data/{name}.png')\n",
    "    plt.clf()\n",
    "\n",
    "    header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "    for i in range(1, 21):\n",
    "        header += f' mfcc{i}'\n",
    "    header += ' label'\n",
    "    header = header.split()\n",
    "\n",
    "    file = open(f'{name}.csv', 'w', newline='')\n",
    "    with file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(header)\n",
    "    # genres = 'discomfort belly_pain burping hungry'.split()\n",
    "    # for g in genres:\n",
    "    #     for filename in os.listdir(f'b_cry/{g}'):\n",
    "    # songname = f'b_cry/{g}/{filename}'\n",
    "#     songname = f'output.wav'\n",
    "    y, sr = librosa.load(songname, mono=True, duration=5)\n",
    "    \n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr,n_mfcc=25)\n",
    "    to_append = f'{name}.wav '   \n",
    "    for e in mfcc:\n",
    "        to_append += f' {np.mean(e)}'\n",
    "    # to_append += f' {model.predict(live_data.iloc[0])}'\n",
    "    #to_append += f' live_data_genre'\n",
    "    file = open(f'{name}.csv', 'a', newline='')\n",
    "    with file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(to_append.split())\n",
    "    live_data = pd.read_csv(f'{name}.csv')\n",
    "    live_data = live_data.drop(['filename'],axis=1)\n",
    "\n",
    "    #print(live_data.iloc[0][0:26])\n",
    "    op=list(to_append.split())\n",
    "    op.pop(0)\n",
    "#     print(Xnew)\n",
    "    Xnew = scaler.transform([op])\n",
    "    ynew = model.predict_classes(Xnew)\n",
    "\n",
    "    print(\"Predicted=%s\" % (ynew))\n",
    "    if ynew==0:\n",
    "        print('Cry')\n",
    "    else:\n",
    "        print('No cry')\n",
    "\n",
    "\n",
    "# def record_audio():\n",
    "for j in range(0,4):\n",
    "    frames = []\n",
    "    songname = \"output\"+str(j)\n",
    "    WAVE_OUTPUT_FILENAME = \"output\"+str(j)+\".wav\"\n",
    "    print(WAVE_OUTPUT_FILENAME)\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "    wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    \n",
    "    print(\"Predicting\")\n",
    "#     for i in range(0,5):\n",
    "#         print(str(i*100))\n",
    "#         time.sleep(0.5)\n",
    "    t2 = threading.Thread(target=predict, args=(songname,))\n",
    "    t2.start()\n",
    "    \n",
    "# if __name__ == \"__main__\":\n",
    "    # creating thread\n",
    "# t1 = threading.Thread(target=record_audio, args=())\n",
    "# t2 = threading.Thread(target=predict, args=())\n",
    "\n",
    "# while(stop==0):\n",
    "# t1.start()\n",
    "# t2.start()\n",
    "# t1.join()\n",
    "# t2.join()\n",
    "# both threads completely executed\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: {0:.2%}\".format(score[1]))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: {0:.2%}\".format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model.save(\"ff_nn_v_Ac88.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights('ff_nn_v_Ac88_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
