{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:35: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:597: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:836: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1097: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1344: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1480: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:152: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  precompute=False, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:320: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, random_state=None,\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:580: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=4 * np.finfo(np.float).eps, n_jobs=None,\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:31: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import keras\n",
    "from keras.layers import  Dropout,Conv2D,Flatten,MaxPool2D\n",
    "from keras import layers\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('inferno')\n",
    "plt.figure(figsize=(8,8))\n",
    "genres = 'cry no_cry'.split()\n",
    "for g in genres:\n",
    "    pathlib.Path(f'img_data/{g}').mkdir(parents=True, exist_ok=True)\n",
    "    for filename in os.listdir(f'ba_cry/{g}'):\n",
    "        songname = f'ba_cry/{g}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=5)\n",
    "        plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
    "        plt.axis('off');\n",
    "        plt.savefig(f'img_data/{g}/{filename[:-3].replace(\".\", \"\")}.png')\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "for i in range(1, 21):\n",
    "    header += f' mfcc{i}'\n",
    "header += ' label'\n",
    "header = header.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('dataset.csv', 'w', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "genres = 'cry no_cry'.split()\n",
    "for g in genres:\n",
    "    for filename in os.listdir(f'ba_cry/{g}'):\n",
    "        songname = f'ba_cry/{g}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=7)\n",
    "        rmse = librosa.feature.rms(y=y)\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        to_append += f' {g}'\n",
    "        file = open('dataset.csv', 'a', newline='')\n",
    "        with file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(to_append.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv('dataset.csv')\n",
    "data.head()# Dropping unneccesary columns\n",
    "data = data.drop(['filename'],axis=1)#Encoding the Labels\n",
    "genre_list = data.iloc[:, -1]\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(genre_list)#Scaling the Feature columns\n",
    "scaler = StandardScaler()\n",
    "# X =np.array(data.iloc[:, :-1], dtype = float)\n",
    "X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))#Dividing data into training and Testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# model.add(Conv2D(16, (3, 3), activation='relu', strides=(1, 1),padding='same', input_shape=X_train.shape[1]))\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu', strides=(1, 1),padding='same')) \n",
    "# model.add(Conv2D(64, (3, 3), activation='relu', strides=(1, 1),padding='same'))\n",
    "# model.add(MaxPool2D ((2, 2)))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6631 - accuracy: 0.54 - 0s 5ms/step - loss: 0.6631 - accuracy: 0.5408\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7008 - accuracy: 0.62 - 0s 8ms/step - loss: 0.7008 - accuracy: 0.6224\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5543 - accuracy: 0.72 - 0s 9ms/step - loss: 0.5543 - accuracy: 0.7245\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5698 - accuracy: 0.73 - 0s 6ms/step - loss: 0.5698 - accuracy: 0.7347\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5464 - accuracy: 0.69 - 0s 8ms/step - loss: 0.5464 - accuracy: 0.6939\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5094 - accuracy: 0.77 - 0s 6ms/step - loss: 0.5094 - accuracy: 0.7755\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5021 - accuracy: 0.74 - 0s 5ms/step - loss: 0.5021 - accuracy: 0.7449\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4843 - accuracy: 0.76 - 0s 22ms/step - loss: 0.4843 - accuracy: 0.7653\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4727 - accuracy: 0.75 - 0s 17ms/step - loss: 0.4727 - accuracy: 0.7551\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4018 - accuracy: 0.80 - 0s 7ms/step - loss: 0.4018 - accuracy: 0.8061\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3729 - accuracy: 0.82 - 0s 7ms/step - loss: 0.3729 - accuracy: 0.8265\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4098 - accuracy: 0.78 - 0s 6ms/step - loss: 0.4098 - accuracy: 0.7857\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3401 - accuracy: 0.83 - 0s 6ms/step - loss: 0.3401 - accuracy: 0.8367\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2826 - accuracy: 0.91 - 0s 6ms/step - loss: 0.2826 - accuracy: 0.9184\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3441 - accuracy: 0.83 - 0s 7ms/step - loss: 0.3441 - accuracy: 0.8367\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3039 - accuracy: 0.84 - 0s 7ms/step - loss: 0.3039 - accuracy: 0.8469\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2610 - accuracy: 0.88 - 0s 8ms/step - loss: 0.2610 - accuracy: 0.8878\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2578 - accuracy: 0.90 - 0s 8ms/step - loss: 0.2578 - accuracy: 0.9082\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2794 - accuracy: 0.89 - 0s 7ms/step - loss: 0.2794 - accuracy: 0.8980\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2467 - accuracy: 0.90 - 0s 6ms/step - loss: 0.2467 - accuracy: 0.9082\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2340 - accuracy: 0.90 - 0s 6ms/step - loss: 0.2340 - accuracy: 0.9082\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2522 - accuracy: 0.91 - 0s 13ms/step - loss: 0.2522 - accuracy: 0.9184\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1420 - accuracy: 0.95 - 0s 9ms/step - loss: 0.1420 - accuracy: 0.9592\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1865 - accuracy: 0.92 - 0s 7ms/step - loss: 0.1865 - accuracy: 0.9286\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1784 - accuracy: 0.92 - 0s 7ms/step - loss: 0.1784 - accuracy: 0.9286\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1372 - accuracy: 0.95 - 0s 10ms/step - loss: 0.1372 - accuracy: 0.9592\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1262 - accuracy: 0.96 - 0s 8ms/step - loss: 0.1262 - accuracy: 0.9694\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1794 - accuracy: 0.92 - 0s 7ms/step - loss: 0.1794 - accuracy: 0.9286\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2006 - accuracy: 0.92 - 0s 6ms/step - loss: 0.2006 - accuracy: 0.9286\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1197 - accuracy: 0.93 - 0s 7ms/step - loss: 0.1197 - accuracy: 0.9388\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1315 - accuracy: 0.93 - 0s 6ms/step - loss: 0.1315 - accuracy: 0.9388\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1097 - accuracy: 0.95 - 0s 13ms/step - loss: 0.1097 - accuracy: 0.9592\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1137 - accuracy: 0.97 - 0s 9ms/step - loss: 0.1137 - accuracy: 0.9796\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0606 - accuracy: 0.98 - 0s 10ms/step - loss: 0.0606 - accuracy: 0.9898\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1756 - accuracy: 0.91 - 0s 6ms/step - loss: 0.1756 - accuracy: 0.9184\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0984 - accuracy: 0.96 - 0s 10ms/step - loss: 0.0984 - accuracy: 0.9694\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1048 - accuracy: 0.95 - 0s 7ms/step - loss: 0.1048 - accuracy: 0.9592\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.98 - 0s 10ms/step - loss: 0.0766 - accuracy: 0.9898\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1122 - accuracy: 0.96 - 0s 25ms/step - loss: 0.1122 - accuracy: 0.9694\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0881 - accuracy: 0.97 - 0s 9ms/step - loss: 0.0881 - accuracy: 0.9796\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0989 - accuracy: 0.96 - 0s 9ms/step - loss: 0.0989 - accuracy: 0.9694\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0649 - accuracy: 0.97 - 0s 20ms/step - loss: 0.0649 - accuracy: 0.9796\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0548 - accuracy: 0.97 - 0s 6ms/step - loss: 0.0548 - accuracy: 0.9796\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0414 - accuracy: 0.98 - 0s 6ms/step - loss: 0.0414 - accuracy: 0.9898\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0678 - accuracy: 0.96 - 0s 6ms/step - loss: 0.0678 - accuracy: 0.9694\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0821 - accuracy: 0.96 - 0s 8ms/step - loss: 0.0821 - accuracy: 0.9694\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0650 - accuracy: 0.96 - 0s 6ms/step - loss: 0.0650 - accuracy: 0.9694\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1046 - accuracy: 0.96 - 0s 7ms/step - loss: 0.1046 - accuracy: 0.9694\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1091 - accuracy: 0.94 - 0s 7ms/step - loss: 0.1091 - accuracy: 0.9490\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0402 - accuracy: 0.97 - 0s 6ms/step - loss: 0.0402 - accuracy: 0.9796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1915ee897b8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,shuffle=True,epochs=50,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* recording\n",
      "* done recording\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 2\n",
    "RATE = 44100\n",
    "RECORD_SECONDS = 5\n",
    "WAVE_OUTPUT_FILENAME = \"output.wav\"\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"* recording\")\n",
    "\n",
    "frames = []\n",
    "\n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "\n",
    "print(\"* done recording\")\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n",
    "wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "wf.setframerate(RATE)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmap = plt.get_cmap('inferno')\n",
    "plt.figure(figsize=(8,8))\n",
    "pathlib.Path(f'live_data/').mkdir(parents=True, exist_ok=True)\n",
    "# for filename in os.listdir(f'b_cry/{g}'):\n",
    "songname = f'output.wav'\n",
    "y, sr = librosa.load(songname, mono=True, duration=7)\n",
    "plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
    "plt.axis('off');\n",
    "plt.savefig(f'live_data/output.png')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "for i in range(1, 21):\n",
    "    header += f' mfcc{i}'\n",
    "header += ' label'\n",
    "header = header.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('predict.csv', 'w', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "# genres = 'discomfort belly_pain burping hungry'.split()\n",
    "# for g in genres:\n",
    "#     for filename in os.listdir(f'b_cry/{g}'):\n",
    "# songname = f'b_cry/{g}/{filename}'\n",
    "songname = f'output.wav'\n",
    "y, sr = librosa.load(songname, mono=True, duration=5)\n",
    "rmse = librosa.feature.rms(y=y)\n",
    "chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "zcr = librosa.feature.zero_crossing_rate(y)\n",
    "mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "to_append = f'output.wav {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'   \n",
    "for e in mfcc:\n",
    "    to_append += f' {np.mean(e)}'\n",
    "# to_append += f' {model.predict(live_data.iloc[0])}'\n",
    "#to_append += f' live_data_genre'\n",
    "file = open('predict.csv', 'a', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(to_append.split())\n",
    "live_data = pd.read_csv('predict.csv')\n",
    "live_data = live_data.drop(['filename'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output.wav\n"
     ]
    }
   ],
   "source": [
    "op=list(to_append.split())\n",
    "print(op.pop(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.40205520391464233', '0.019040800631046295', '2029.287070207813', '2492.9662724210903', '4587.3199462890625', '0.05556685836226852', '-352.869140625', '100.57908630371094', '10.353883743286133', '15.111245155334473', '6.137244701385498', '1.810538411140442', '-7.785067081451416', '8.381434440612793', '-5.35196590423584', '16.317611694335938', '1.39741051197052', '4.00768518447876', '6.031613349914551', '-3.389061212539673', '4.086082935333252', '9.323531150817871', '-6.910163402557373', '7.099420547485352', '-0.2120068520307541', '4.200275897979736']\n",
      "[[-1.26592688e-01 -7.14185881e-01 -3.06876729e-01  5.27057018e-01\n",
      "   2.34328967e-04 -8.91113351e-01 -3.12259516e-01  1.02326634e+00\n",
      "   1.01659183e+00  7.33190136e-01  8.83629830e-01 -1.99488609e-01\n",
      "  -1.56417889e-01  3.80499371e-01 -5.88635751e-01  1.71146650e+00\n",
      "   2.20608464e-01  1.86673715e-01  9.81535019e-01 -8.71235627e-01\n",
      "   5.56513848e-01  7.10579287e-01 -1.18968169e+00  6.48530049e-01\n",
      "   1.99159960e-01  2.23600507e-01]]\n",
      "Predicted=[1]\n",
      "No cry\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(live_data.iloc[0][0:26])\n",
    "\n",
    "print(op)\n",
    "Xnew = scaler.transform([op])\n",
    "print(Xnew)\n",
    "ynew = model.predict_classes(Xnew)\n",
    "print(\"Predicted=%s\" % (ynew))\n",
    "if ynew==0:\n",
    "    print('Cry')\n",
    "else:\n",
    "    print('No cry')\n",
    "#live_data = data.drop(['filename'],axis=1)\n",
    "#print(model.predict(live_data.iloc[:, -1]))\n",
    "# print(type(live_data.iloc[0]))\n",
    "#print(model.predict_classes(live_data.iloc[0]))\n",
    "# print(live_data.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 100.00%\n",
      "Testing Accuracy: 92.00%\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: {0:.2%}\".format(score[1]))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: {0:.2%}\".format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* recording\n",
      "output0.wav\n",
      "Predicting\n",
      "output1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-14:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-6-5ac50552d28a>\", line 84, in predict\n",
      "    Xnew = scaler.transform([op])\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\", line 763, in transform\n",
      "    X -= self.mean_\n",
      "ValueError: operands could not be broadcast together with shapes (1,26) (40,) (1,26) \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting\n",
      "output2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-15:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-6-5ac50552d28a>\", line 84, in predict\n",
      "    Xnew = scaler.transform([op])\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\", line 763, in transform\n",
      "    X -= self.mean_\n",
      "ValueError: operands could not be broadcast together with shapes (1,26) (40,) (1,26) \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting\n",
      "output3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-16:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-6-5ac50552d28a>\", line 84, in predict\n",
      "    Xnew = scaler.transform([op])\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\", line 763, in transform\n",
      "    X -= self.mean_\n",
      "ValueError: operands could not be broadcast together with shapes (1,26) (40,) (1,26) \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-17:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-6-5ac50552d28a>\", line 84, in predict\n",
      "    Xnew = scaler.transform([op])\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\", line 763, in transform\n",
      "    X -= self.mean_\n",
      "ValueError: operands could not be broadcast together with shapes (1,26) (40,) (1,26) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import pathlib\n",
    "import threading\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# t1 = threading.Thread(target=print_square, args=(10,))\n",
    "# t2 = threading.Thread(target=print_cube, args=(10,))\n",
    "\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 2\n",
    "RATE = 44100\n",
    "RECORD_SECONDS = 6\n",
    "WAVE_OUTPUT_FILENAME = \"output.wav\"\n",
    "\n",
    "stop = 0\n",
    "\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"* recording\")\n",
    "\n",
    "\n",
    "def predict(name):\n",
    "    #Doing prediction\n",
    "    cmap = plt.get_cmap('inferno')\n",
    "    plt.figure(figsize=(8,8))\n",
    "    pathlib.Path(f'live_data/').mkdir(parents=True, exist_ok=True)\n",
    "    # for filename in os.listdir(f'b_cry/{g}'):\n",
    "    songname = name+'.wav'\n",
    "    y, sr = librosa.load(songname, mono=True, duration=7)\n",
    "    plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
    "    plt.axis('off');\n",
    "    plt.savefig(f'live_data/{name}.png')\n",
    "    plt.clf()\n",
    "\n",
    "    header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "    for i in range(1, 21):\n",
    "        header += f' mfcc{i}'\n",
    "    header += ' label'\n",
    "    header = header.split()\n",
    "\n",
    "    file = open(f'{name}.csv', 'w', newline='')\n",
    "    with file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(header)\n",
    "    # genres = 'discomfort belly_pain burping hungry'.split()\n",
    "    # for g in genres:\n",
    "    #     for filename in os.listdir(f'b_cry/{g}'):\n",
    "    # songname = f'b_cry/{g}/{filename}'\n",
    "#     songname = f'output.wav'\n",
    "    y, sr = librosa.load(songname, mono=True, duration=5)\n",
    "    rmse = librosa.feature.rms(y=y)\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "    to_append = f'{name}.wav {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'   \n",
    "    for e in mfcc:\n",
    "        to_append += f' {np.mean(e)}'\n",
    "    # to_append += f' {model.predict(live_data.iloc[0])}'\n",
    "    #to_append += f' live_data_genre'\n",
    "    file = open(f'{name}.csv', 'a', newline='')\n",
    "    with file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(to_append.split())\n",
    "    live_data = pd.read_csv(f'{name}.csv')\n",
    "    live_data = live_data.drop(['filename'],axis=1)\n",
    "\n",
    "    #print(live_data.iloc[0][0:26])\n",
    "    op=list(to_append.split())\n",
    "    op.pop(0)\n",
    "#     print(Xnew)\n",
    "    Xnew = scaler.transform([op])\n",
    "    ynew = model.predict_classes(Xnew)\n",
    "\n",
    "    print(\"Predicted=%s\" % (ynew))\n",
    "    if ynew==0:\n",
    "        print('Cry')\n",
    "    else:\n",
    "        print('No cry')\n",
    "\n",
    "\n",
    "# def record_audio():\n",
    "for j in range(0,4):\n",
    "    frames = []\n",
    "    songname = \"output\"+str(j)\n",
    "    WAVE_OUTPUT_FILENAME = \"output\"+str(j)+\".wav\"\n",
    "    print(WAVE_OUTPUT_FILENAME)\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "    wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    \n",
    "    print(\"Predicting\")\n",
    "#     for i in range(0,5):\n",
    "#         print(str(i*100))\n",
    "#         time.sleep(0.5)\n",
    "    t2 = threading.Thread(target=predict, args=(songname,))\n",
    "    t2.start()\n",
    "    \n",
    "# if __name__ == \"__main__\":\n",
    "    # creating thread\n",
    "# t1 = threading.Thread(target=record_audio, args=())\n",
    "# t2 = threading.Thread(target=predict, args=())\n",
    "\n",
    "# while(stop==0):\n",
    "# t1.start()\n",
    "# t2.start()\n",
    "# t1.join()\n",
    "# t2.join()\n",
    "# both threads completely executed\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model1 = load_model('ff_nn_v1_Ac85.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model.save(\"ff_nn_v2_Ac92.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import fft\n",
    "from scipy.io import wavfile # get the api\n",
    "fs, data = wavfile.read('output3.wav') # load the data\n",
    "a = data.T[0] # this is a two channel soundtrack, I get the first track\n",
    "b=[(ele/2**8.)*2-1 for ele in a] # this is 8-bit track, b is now normalized on [-1,1)\n",
    "c = fft(b) # calculate fourier transform (complex numbers list)\n",
    "d = len(c)/2  # you only need half of the fft list (real signal symmetry)\n",
    "plt.plot(abs(c[0:(5-1)]),'r') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
