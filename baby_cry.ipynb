{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:35: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:597: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:836: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1097: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1344: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1480: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:152: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  precompute=False, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:320: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, random_state=None,\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:580: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=4 * np.finfo(np.float).eps, n_jobs=None,\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:31: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import layers\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmap = plt.get_cmap('inferno')\n",
    "plt.figure(figsize=(8,8))\n",
    "genres = 'cry no_cry'.split()\n",
    "for g in genres:\n",
    "    pathlib.Path(f'img_data/{g}').mkdir(parents=True, exist_ok=True)\n",
    "    for filename in os.listdir(f'b_cry/{g}'):\n",
    "        songname = f'b_cry/{g}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=7)\n",
    "        plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
    "        plt.axis('off');\n",
    "        plt.savefig(f'img_data/{g}/{filename[:-3].replace(\".\", \"\")}.png')\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "for i in range(1, 16):\n",
    "    header += f' mfcc{i}'\n",
    "header += ' label'\n",
    "header = header.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('dataset.csv', 'w', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "genres = 'cry no_cry'.split()\n",
    "for g in genres:\n",
    "    for filename in os.listdir(f'b_cry/{g}'):\n",
    "        songname = f'b_cry/{g}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=30)\n",
    "        rmse = librosa.feature.rms(y=y)\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        to_append += f' {g}'\n",
    "        file = open('dataset.csv', 'a', newline='')\n",
    "        with file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(to_append.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset.csv')\n",
    "data.head()# Dropping unneccesary columns\n",
    "data = data.drop(['filename'],axis=1)#Encoding the Labels\n",
    "genre_list = data.iloc[:, -1]\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(genre_list)#Scaling the Feature columns\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))#Dividing data into training and Testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.5732 - accuracy: 0.0000e+ - 0s 5ms/step - loss: 2.5591 - accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.1181 - accuracy: 0.29 - 0s 4ms/step - loss: 2.1123 - accuracy: 0.3111\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8005 - accuracy: 0.82 - 0s 6ms/step - loss: 1.7920 - accuracy: 0.8148\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5236 - accuracy: 0.82 - 0s 5ms/step - loss: 1.5136 - accuracy: 0.8222\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2534 - accuracy: 0.82 - 0s 6ms/step - loss: 1.2501 - accuracy: 0.8222\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0174 - accuracy: 0.83 - 0s 5ms/step - loss: 1.0094 - accuracy: 0.8444\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8080 - accuracy: 0.85 - 0s 5ms/step - loss: 0.8065 - accuracy: 0.8519\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6428 - accuracy: 0.85 - 0s 8ms/step - loss: 0.6496 - accuracy: 0.8519\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5443 - accuracy: 0.85 - 0s 6ms/step - loss: 0.5374 - accuracy: 0.8593\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4580 - accuracy: 0.86 - 0s 5ms/step - loss: 0.4580 - accuracy: 0.8667\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4081 - accuracy: 0.86 - 0s 5ms/step - loss: 0.4029 - accuracy: 0.8667\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3608 - accuracy: 0.89 - 0s 7ms/step - loss: 0.3642 - accuracy: 0.9037\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3460 - accuracy: 0.90 - 0s 6ms/step - loss: 0.3401 - accuracy: 0.9111\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3214 - accuracy: 0.89 - 0s 7ms/step - loss: 0.3138 - accuracy: 0.9037\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2733 - accuracy: 0.91 - 0s 6ms/step - loss: 0.2737 - accuracy: 0.9185\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2366 - accuracy: 0.93 - 0s 5ms/step - loss: 0.2360 - accuracy: 0.9333\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2023 - accuracy: 0.95 - 0s 5ms/step - loss: 0.2079 - accuracy: 0.9481\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1795 - accuracy: 0.94 - 0s 7ms/step - loss: 0.1857 - accuracy: 0.9481\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1688 - accuracy: 0.95 - 0s 6ms/step - loss: 0.1664 - accuracy: 0.9556\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1494 - accuracy: 0.96 - 0s 6ms/step - loss: 0.1484 - accuracy: 0.9630\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1365 - accuracy: 0.96 - 0s 7ms/step - loss: 0.1334 - accuracy: 0.9704\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1220 - accuracy: 0.97 - 0s 6ms/step - loss: 0.1195 - accuracy: 0.9778\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1095 - accuracy: 0.97 - 0s 7ms/step - loss: 0.1084 - accuracy: 0.9778\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1020 - accuracy: 0.97 - 0s 5ms/step - loss: 0.0983 - accuracy: 0.9778\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0824 - accuracy: 0.97 - 0s 4ms/step - loss: 0.0865 - accuracy: 0.9778\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0741 - accuracy: 0.99 - 0s 6ms/step - loss: 0.0750 - accuracy: 0.9926\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0672 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0668 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0659 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0634 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0611 - accuracy: 0.9926\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0519 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0526 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0427 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0373 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0355 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0353 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 0.99 - 0s 4ms/step - loss: 0.0347 - accuracy: 0.9926\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 0.99 - 0s 4ms/step - loss: 0.0335 - accuracy: 0.9926\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 1.00 - 0s 7ms/step - loss: 0.0306 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 1.00 - 0s 6ms/step - loss: 0.0266 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 1.00 - 0s 6ms/step - loss: 0.0225 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0192 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0192 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0172 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0163 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 1.00 - 0s 6ms/step - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 1.00 - 0s 6ms/step - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 1.00 - 0s 6ms/step - loss: 0.0083 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "classifier = model.fit(X_train,y_train,shuffle=True,epochs=50,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-63fe2123deac>:1: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(generator=X_test, steps=50)#OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* recording\n",
      "* done recording\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 2\n",
    "RATE = 44100\n",
    "RECORD_SECONDS = 5\n",
    "WAVE_OUTPUT_FILENAME = \"output.wav\"\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"* recording\")\n",
    "\n",
    "frames = []\n",
    "\n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "\n",
    "print(\"* done recording\")\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n",
    "wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "wf.setframerate(RATE)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cmap = plt.get_cmap('inferno')\n",
    "plt.figure(figsize=(8,8))\n",
    "pathlib.Path(f'live_data/').mkdir(parents=True, exist_ok=True)\n",
    "# for filename in os.listdir(f'b_cry/{g}'):\n",
    "songname = f'output.wav'\n",
    "y, sr = librosa.load(songname, mono=True, duration=7)\n",
    "plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
    "plt.axis('off');\n",
    "plt.savefig(f'live_data/output.png')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "for i in range(1, 16):\n",
    "    header += f' mfcc{i}'\n",
    "header += ' label'\n",
    "header = header.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('predict.csv', 'w', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "# genres = 'discomfort belly_pain burping hungry'.split()\n",
    "# for g in genres:\n",
    "#     for filename in os.listdir(f'b_cry/{g}'):\n",
    "# songname = f'b_cry/{g}/{filename}'\n",
    "songname = f'output.wav'\n",
    "y, sr = librosa.load(songname, mono=True, duration=5)\n",
    "rmse = librosa.feature.rms(y=y)\n",
    "chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "zcr = librosa.feature.zero_crossing_rate(y)\n",
    "mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "to_append = f'output.wav {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'   \n",
    "for e in mfcc:\n",
    "    to_append += f' {np.mean(e)}'\n",
    "# to_append += f' {model.predict(live_data.iloc[0])}'\n",
    "#to_append += f' live_data_genre'\n",
    "file = open('predict.csv', 'a', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(to_append.split())\n",
    "live_data = pd.read_csv('predict.csv')\n",
    "live_data = live_data.drop(['filename'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.49939677e+03  1.24744557e-01 -2.78122620e+02  1.31338074e+02\n",
      "  -8.87330933e+01 -4.91475630e+00  8.92387199e+00 -5.33820877e+01\n",
      "  -6.17922878e+00  8.00373936e+00 -1.41683397e+01  1.10049124e+01\n",
      "  -1.08737662e-01 -1.57673702e+01  7.95671320e+00 -2.77607751e+00\n",
      "  -1.21360607e+01  8.09323883e+00  8.44810069e-01 -3.53708744e+00\n",
      "   7.11395216e+00]]\n",
      "Predicted=[1]\n"
     ]
    }
   ],
   "source": [
    "#print(live_data.iloc[0][0:26])\n",
    "Xnew = np.array([live_data.iloc[0][0:21]])\n",
    "print(Xnew)\n",
    "ynew = model.predict_classes(Xnew)\n",
    "print(\"Predicted=%s\" % (ynew))\n",
    "#live_data = data.drop(['filename'],axis=1)\n",
    "#print(model.predict(live_data.iloc[:, -1]))\n",
    "# print(type(live_data.iloc[0]))\n",
    "#print(model.predict_classes(live_data.iloc[0]))\n",
    "# print(live_data.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#p_pred=model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict_classes(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test=y_test.astype('int64')\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9411764705882353"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asd=model.predict_classes(np.array([live_data.iloc[0][0:21]]))\n",
    "asd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
